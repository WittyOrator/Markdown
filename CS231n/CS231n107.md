#CS231n 2018 课程笔记 模块一 07#
[神经网络 第3部分：学习和评估](http://cs231n.github.io/neural-networks-2/)
----------
这一部分主要讨论建立网络之后如何进行学习，内容包括：

1. **梯度检查**
2. **合理性检查**
3. **监控学习过程**
4. **参数更新**
5. **超参数优化**
6. **模型集成**

##1.学习##
前面的部分讨论了神经网络中的静态内容：如何构建网络、数据和损失函数。这个部分将介绍网络中的动态部分：如何对参数进行学习并找到最优的超参数。

###1.1 梯度检查
理论上，进行梯度检查就是简单比较解析梯度和数值梯度，但是实践中这个过程更加复杂和易出错。下面是一些关于梯度检查的提示、技巧和需要注意的问题：

**使用中心差分公式**
$$\frac{df(x)}{dx} = \frac{f(x + h) - f(x)}{h} \hspace{0.1in} \text{(前向差分，误差项为} O(h) \text{)}$$
$$\frac{df(x)}{dx} = \frac{f(x) - f(x - h)}{h} \hspace{0.1in} \text{(后向差分，误差项为} O(h) \text{)}$$
$$\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in} \text{(中心差分，误差项为} O(h^2) \text{)}$$
上面是三种数值梯度计算方式，其中\\(h\\)的值非常小，实际一般大概为1e-5左右，所以中心差分拥有较小的误差。

**使用相对误差进行比较**
$$\frac{\mid f'\_a - f'\_n \mid}{\max(\mid f'\_a \mid, \mid f'\_n \mid)}$$
\\(f'\_a\\)为解析梯度，\\(f'\_n\\)为数值梯度，一般可参考的判断标准为：

- \\(f'\_a > 10^{-2}\\)，算错了。
- \\(10^{-4} < f'\_a < 10^{-2}\\)，你有些不适，这很尴尬，应该是错了。
- \\(10^{-7} < f'\_a < 10^{-4}\\)，如果目标函数有不可导点则可以接受，没有误差就偏大了。
- \\(f'\_a < 10^{-7}\\)，算对了。

记住，当网络层数越深，相对误差会越大。一个10层的网络，BP到前面几层\\(10^{-2}\\)的误差也许是可以接受的。

**精度问题**

Python3默认使用双精度，保证17位十进制精度。

- 如果不知道哪里算错了，可以检查下是否使用了单精度变量。
- 当梯度值过小时，比如大概1e-10，相对误差计算也可能过大。（[计算机结构问题](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)）
- \\(h\\)值不要过小，一般在1e-4到1e-6之间。

**目标函数的不可导点**

目标函数存在不可导点，此处无法计算解析梯度，但是数值梯度有值。比如在ReLU的0点，解析梯度为0，数值梯度则有值。这种情况很常见，ReLU和SVM中都存在不可导点。检查少一些的数据点有利于避开不可导点，一般几个数据点正确整批数据都没问题，这样使梯度检查更有效率。

**不要让正则化项压过数据**

有一种情况需要注意，正则化项的损失盖过了数据的损失。解决方式是每次检查时，先检查一次不带正则化项的梯度，再加上正则化项检查一次。

**记得关掉随机失活**

在进行梯度检查时，记得关掉随机失活等不确定的影响，因为这些操作很明显会使数值梯度产生巨大误差。关掉这些操作将无法对它们进行梯度检查（例如随机失活没有正确的反向传播）。一个更好的办法是在计算f(x+h)和f(x-h)和计算解析梯度前强制使用一个特定的随机种子。

**只检查少量的维度**

在实践中可能有几百万个参数，在这种情况下实际只能检查其中的一些维度而假设其它的都是正确的。需要注意的是，要保证检查这些维度中的所有不同参数。比如没有检查偏差\\(b\\)的梯度，此时错误梯度可能将被忽略。

###1.2 在学习之前：合理性检查的提示和技巧###
**从概率表现寻找正确的损失值**

弄清楚用随机初始化后期望的初始损失值是多少并检验（此时关掉正则化项）。比如使用Softmax分类器分类CIFAR-10图片，期望的初始损失值是-ln(0.1) = 2.302。（因为随机参数分类图片的正确率是0.1）

**第二个合理性检查是损失值随着正则化项增大而增大**

**过拟合一个小数据集**

最后也是最重要的，在你训练整个数据集之前，使用一个小的数据集（例如20个样本）进行训练，确保能够达到0损失。（关掉正则化项，它会阻碍你获得0损失）

###1.3 监控学习过程###
在神经网络训练阶段有很多有用的数值需要监控，这些数值的图表能让你直观的感受不同超参数的影响并有效率的调整这些超参数。这些图表的x轴一般都是epoch数（将所有样本过一遍是一个epoch）。

**损失函数**

在训练中损失值是第一重要的数值，并且在每个batch都记录它。下面的图表表现了不同的学习率下损失值的变化情况：

![](http://cs231n.github.io/assets/nn3/learningrates.jpeg)

单独的损失值随时间变化的图表如下：

![](http://cs231n.github.io/assets/nn3/loss.jpeg)

在上图中，上下波动的幅度和batch的大小有关（每次梯度更新都会改进损失函数），batch的大小越大波动幅度越小。

**训练/验证 准确率**

在训练一个分类器时第二重要的数值是训练/验证的准确率。这个图表揭示了你的模型的过拟合程度。

![](http://cs231n.github.io/assets/nn3/accuracies.jpeg)

在上图中，训练准确率和验证准确率之间的差距反应了模型的过拟合程度，差距越大过拟合程度越大。在过拟合时，可以增大正则化项、加大随机失活概率或用更多数据验证。还有一种情况是模型本身的容量不够，这时需要增加参数使用更大的模型。

**权值变化率**

最后一个你可能需要跟踪的数值是权值变化率，它的计算如下列代码，一个合适的变化率大概在1e-3附近。

	# W是权值，dW是权值的梯度
	param_scale = np.linalg.norm(W.ravel())
	update = -learning_rate*dW # SGD
	update_scale = np.linalg.norm(update.ravel())
	W += update # 权值更新量
	print update_scale / param_scale # 应该在 1e-3 附近

**每层的激活/梯度分布**

一个错误的初始化可以使学习过程变慢或完全停止。幸运的是，这个问题可以使用所有层的激活/梯度直方图观察到。例如一个tanh神经元应该有[-1,1]的分布，而不是全0或全部集中在-1或1附近。

**可视化第一层权值**

在处理图片像素时，将第一层权值可视化可能会有帮助（在SVM和Softmax作业的最后展示过）。

###1.4 参数更新###
一旦计算出解析梯度，它将被用来更新参数，接下来介绍一些更新参数的方法（参数都用x表示）：

####1.4.1 SGD####
**Vanilla更新** 最简单的参数更新方式，以梯度的负方向更新参数

	# Vanilla更新
	x += - learning_rate * dx

**动量（Momentum）更新**

另一种在深度网络中获得更快收敛速度的更新方法，它从物理视角看待优化问题。我们把损失值看作是山地上某个位置的高度，将参数初始化为随机值相当于在山地上某个位置设置了一个速度为0的小球，而优化过程可以看作让小球从上述位置滚下来。

在普通SGD中，位置变化量直接由梯度决定，而在动量版本中，梯度影响速度，而速度决定位置变化量。

	# 动量更新
	v = mu*v - learning_rate*dx # 速度
	x += v # 更新量等于速度

速度v初始值为0，摩擦系数mu为超参数（一般取值为0.9左右，可以尝试[0.5, 0.9, 0.95, 0.99]）。上面的式子很好理解，`mu*v`表示速度越快摩擦阻力越大，而梯度（坡度）dx越大速度越快。

**涅斯特罗夫动量（Nesterov Momentum）**

现在流行的对动量更新的改进版本，取得了比标准动量更新稍微好一些的表现。

	v_prev = v
	v = mu*v - learning_rate*dx # 速度
	x += v + mu*(v - v_prev) 

建议看看有关涅斯特罗夫加速动量（NAG，Nesterov’s Accelerated Momentum）的扩展阅读：

- [Advances in optimizing Recurrent Networks](https://arxiv.org/pdf/1212.0901v2.pdf), 章节3.5。
- [Ilya Sutskever’s thesis](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)，章节7.2。

####1.4.2 学习率退火####
在深度学习训练中，一般随着时间的推移减小学习率，下面是三种常见的减小学习率的方法：

- 逐步递减：每经过一定的epoch数就用某个因子(比如0.9)减小学习率，5个epoch后学习率降低到大约原来的\\(0.9^5=0.59\\)，20个epoch后降为原来的\\(0.9^{20}=0.12\\)。
- 指数递减：\\(\alpha = \alpha\_0 e^{-k t}\\)，\\(\alpha\_0, k\\)为超参数，t为epoch数。
- 1/t递减：\\(\alpha = \alpha\_0 / (1 + k t )\\)，\\(\alpha\_0, k\\)为超参数，t为epoch数。

在实践中逐步递减更可行，如果你的计算资源足够，可以让递减缓慢些。

####1.4.3 二阶法####
第二种在深度学习中常用的优化方法是牛顿法，它的更新表达式为：
$$x \leftarrow x - [H f(x)]^{-1} \nabla f(x)$$
\\(H f(x)\\)是海森矩阵，它是函数的二阶偏导数的平方矩阵，描述了函数的局部曲率。和海森矩阵的逆矩阵相乘表示在曲率小的地方大步前进，在曲率大的地方小步前进。关键是这个公式里没有超参数，这是相对一阶方法的巨大进步。

尽管如此，但是牛顿法对绝大多数深度学习应用来说都不切实际，因为计算海森矩阵和它的逆矩阵开销非常大。

实际上，在大规模网络中一阶方法应用更常见，因为它们简单。

####1.4.4 逐参数适应学习率法####
所有之前讨论的方法对每个参数的学习率都是一样的。调整学习率是一个开销很大的过程，所以在设计自适应调整学习率甚至对每个参数进行自适应调整的方法上作了很多的工作。下面介绍一些实践中可能遇到的自适应方法：

**Adagrad**

	cache += dx**2
	x += - learning_rate * dx / (np.sqrt(cache) + eps)

`eps`取1e-4到1e-8，防止除0。

**RMSprop**

	cache = decay_rate * cache + (1 - decay_rate) * dx**2
	x += - learning_rate * dx / (np.sqrt(cache) + eps)

`decay_rate`是一个超参数，常用值为[0.9, 0.99, 0.999]。

**Adam**

	m = beta1*m + (1-beta1)*dx
	mt = m / (1-beta1**t)
	v = beta2*v + (1-beta2)*(dx**2)
	vt = v / (1-beta2**t)
	x += - learning_rate * mt / (np.sqrt(vt) + eps)

论文推荐的`eps = 1e-8, beta1 = 0.9, beta2 = 0.999`。

![](http://cs231n.github.io/assets/nn3/opt2.gif)

上面的动画直观的反应了几种优化方式的区别。

###1.5 超参数优化###
训练神经网络的过程中涉及很多超参数，主要的有三个：

- 初始的学习率
- 学习率的递减率
- 正则化强度

如前面介绍，除了这三个主要的超参数，其实还有更多不太敏感的超参数。下面额外介绍一些优化超参数的提示和技巧：

**实现方式**

大型的神经网络需要很长时间去训练，尝试超参数需要很多天甚至几星期。一种特别的设计是用一些“工人程序”去持续的对超参数进行采样和验证，“工人程序”会将验证的各个阶段性结果（checkpoints）写入文件。在系统中还有一个“调度程序”，它负责管理所有的“工人程序”，并且对“工人程序”写入的结果进行检查并进行统计。

**使用一个验证集代替交叉验证**

在大多数情况下，一个大小可观的验证集可以简化代码，而不需要用交叉验证把代码分成几部分。

**超参数范围**

在指数尺度上进行超参数搜索，对学习率的一个典型的采样可能像这样：`learning_rate = 10 ** uniform(-6, 1)`，即从均匀分布中随机生成一个数字，然后让它成为10的幂。对于正则化强度也应该采取同样的策略，这是因为它们对训练力度有乘法效应。而对于随机失活概率就应该采用原始的尺度：`dropout = uniform(0,1))`。

**使用随机搜索代替网格搜索**

![](http://cs231n.github.io/assets/nn3/gridsearchbad.jpeg)

对超参数优化，随机选择比网格化的选择更加有效率，而且在实践中也更容易实现。

**注意边界上的最优值**

如果找到的最优值，应该再检查一下是不是在边界上，以免错过好的搜索范围。

**从粗到细搜索**

从大的范围开始搜索，先用较少的数据找到更小的范围，然后用较多的数据在更小的范围上搜索，如此迭代。

**贝叶斯超参数优化**

这是一个研究领域，致力于找到更加有效的探索超参数空间的算法。更多的信息可以看[这里](http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html)。

##2.模型集成##
在实践中，一个可靠的提高神经网络性能几个百分点的的方法是训练多个单独的模型，然后在测试时平均它们的预测结果。当集成的模型数增加时，性能通常也单调提升。此外，这种提升和集成的模型多样相关。下面是一些模型集成的方式：

- **一样的模型，不同的初始化** 用交叉验证确定最优的超参数，然后用最优的超参数和随机的的初始化参数训练多个模型。
- **用交叉验证发现最好的模型** 用交叉验证确定最优的超参数，然后选择其中最好的几个模型来集成。
- **一个模型的不同记录点** 如果训练开销特别大，那就用一个模型的多个不同记录点进行集成，有些人也用这种方式取得了有限的成功。很明显，这种方法缺乏多样性。
- **在训练时跑参数的平均值** 和上一个方法类似，一个能增加一两个百分比的廉价的方法是在内存中保持一份权值拷贝，这个拷贝是之前训练中权值的指数衰减和（an exponentially decaying sum，水平有限，这个地方不清楚，更多信息请看[原文](http://cs231n.github.io/neural-networks-3/)）

模型集成的一个缺点是用很长时间取评估测试样本。感兴趣的读者可能发现最近Geoff Hinton在“[Dark Knowledge](https://www.youtube.com/watch?v=EK61htlw8hY)”上的工作令人鼓舞，它通过将集成的对数似然估计纳入到修改的目标函数中，从一个好的集成回溯到一个单独模型。

##总结##

- **用一个小的batch来对你的解析梯度进行梯度检查并注意各种问题。**
- **对于合理性检查，确认你的初始损失值，还有你能在一小块数据上获得0损失。**
- **在训练中，监控损失值，训练/验证准确率还有权值变化率（应该在1e-3左右），CNN的话还有第一层权值。**
- **两个建议的参数更新方法是SGD+Nesterov动量和Adam。**
- **逐步的降低学习率。**
- **随机搜索超参数，逐步细化超参数。**
- **进行模型集成获得额外的性能。**

附加参考文献

- [SGD tips and tricks](https://www.microsoft.com/en-us/research/publication/stochastic-gradient-tricks/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F192769%2Ftricks-2012.pdf) 
- [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
- [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/pdf/1206.5533v2.pdf)

---
© 2018 by 0ne.tech