#CS231n 2018 课程笔记 模块二 01#
[卷积神经网络：架构，卷积/池化层](http://cs231n.github.io/convolutional-networks/)
----------
这一部分主要讨论建立网络之后如何进行学习，内容包括：

1. **CNNs架构概览**
2. **CNNs各层介绍**
3. **CNNs框架介绍**
4. **附加参考**

#卷积神经网络（CNNs/ConvNets)#
卷积神经网络与普通的神经网络非常类似：它们都是由神经元组成并拥有可以训练的权值和偏差。整个网络仍然表示一个可导的评分函数：从原始的图片像素开始到各类型的得分结束。在最后的输出层它们也都有损失函数（比如SVM或Softmax），并且普通神经网络上的技巧同样能在CNNs中应用。

那么什么改变了呢？CNNs假设输入都是图片，这样允许我们在架构上能对特定的属性编码，这些变化能够实现和大量减少网络中的参数使前向函数更有效率。

##1.架构概览##
回忆之前课程所讲的常规神经网络，网络接收一个向量输入，然后通过多个隐层对其进行变换。每个隐层由一组神经元组成，其中的每个神经元都与前一层的所有神经元进行全连接，它们的功能都是独立的且不共享任何连接。最后一个被全连接的层叫做输出层，在分类应用中它表现为各类型得分。

常规的神经网络不能适应完全的图片数据。在CIFAR-10中，图片的大小只有32x32x3(32像素宽，32像素高，3个颜色通道)，所以常规神经网络中在首个隐层中的一个全连接神经元应该有32*32*3=3072个权值。这个数量看上去可以管理，但是很明显全连接结构不能适应更大的图片。例如一个更大分辨率的图片（200x200x3）会使神经元拥有200*200*3=120000个权值。进一步说，我们显然需要一些这样的神经元，所以参数数量会快速的上升。很明显这种情况下全连接是没用的，而且巨量的参数会快速导致过拟合。

三维神经元排列。CNNs改变了输入是由图片组成的事实并使用了一种更明智的架构。CNNs层中的神经元按3个维度排列而成：**宽度，高度，深度**。（注意这里的深度不是网络层数）。我们很快会看到在一个CNNs层中的神经元只连接上一层的一小块区域而不是全连接。进一步说，分类CIFAR-10的输出层的纬度为1x1x10，因为在CNNs架构的最后我们将完全的图片缩减成了一个各类型得分的向量。

![](http://cs231n.github.io/assets/nn1/neural_net2.jpeg)

普通的三层神经网络。

![](http://cs231n.github.io/assets/cnn/cnn.jpeg)

一个CNNs将它的神经元排列成三维结构，每一层将3D数据块转换为3D输出块。在这幅图中，宽和高是图片的分辨率而深度是图片的颜色通道数（红绿蓝）

**一个CNNs由多个层组成，每个层拥有一个简单的API：将输入3D块用可导的函数转换为输出3D块，函数中可能有参数也可能没有。**

##2.CNNs中的各种层##
如上锁描述，一个简单的CNNs是由一连串层组成，每个层通过一个可导函数将一个块转换为另一个块。我们用三个主要类型的层来构建CNNs：**卷积层（Convolutional Layer），池化层（Pooling Layer）和 全连接层（Fully-Connected Layer）**。我们将会堆叠这些层来形成一个完整的CNNs架构。

样例架构概览。我们将会在下面涉及更多细节，但是一个简单的分类CIFAR-10的CNNs应该有这种架构[输入层-卷积层-RELU层-池化层-全连接层]，具体如下：

- 输入层（**INPUT**）[32x32x3]将会持有原始的图片像素（32像素宽，32像素高，3个颜色通道RGB）
- 卷积层（**CONV**）将会计算输入中的局部区域的输出，每一个层计算它的权值和它连接的局部区域的点积。结果可能是一个大小为[32x32x12]的块，如果我们选择用12个过滤器。
- ReLU层（**RELU**）将应用激活函数处理输入，比如\\(max(0,x)\\),输出大小不变为[32x32x12]。
- 池化层（**POOL**）将对空间维度（宽和高）做下采样操作，结果大小可能是[16x16x12]。
- 全连接层（**FC**）将会计算出各类型得分，结果的块大小为[1x1x10]。像它的名字一样，这一层的所有神经元都会和上一层的所有神经元相连。

在这种方式下，CNNs通过一层又一层操作将原始图片像素值转换为最终的类型得分。注意一些层是有参数的而另一些是没有参数的。具体来说，卷积层和全连接层的变换操作不仅是激活输入块，还包括其它参数（神经元的权重和偏差），而ReLU层和池化层只进行固定的操作。卷积层和全连接层中的参数通过梯度下降进行训练使得CNNs算出的类型得分和训练集中图片的真实类型标签一致。

概括：

- 一个CNNs架构的最简单的例子是将图像块通过一连串层转换为输出块（比如类型得分向量）
- 其中有一些不同类型的层（例如CONV/FC/RELU/POOL是最常见的，大写表示层）
- 每一层接受一个3D块输入然后通过一个可导函数转换为一个3D块输出
- 每一层有或没有参数（例如CONV/FC有，RELU/POOL没有）
- 每一层有或没有附加的超参数（例如CONV/FC/POOL有，RELU没有）

![](http://cs231n.github.io/assets/cnn/convnet.jpeg)

这是一个CNNs架构的例子，最左边的初始块存储原始图片像素，最右边的输出块存储类型得分，它只显示了得分最高的5种类型。接下来我们将描述各个独立的层和各层中的细节。

###2.1 卷积层（CONV）###
卷积层是CNNs的核心构建模块，它承担了绝大多数计算任务。

**不涉及大脑分析的简介。**让我们首先不从分析大脑神经元的角度来讨论CONV，它的参数由一组可学习的过滤器组成。每一个过滤器在空间维度上很小（比输入块的空间维度小），但是延伸到输入块的全部深度。例如一个作用于第一层的大小为5x5x3的过滤器（5像素宽，5像素高，3个颜色通道）。在向前的方向上，我们用每个过滤器在输入块的空间维度上滑动（从左到右，从上到下）并计算过滤器和当前位置的点积。直观的，网络将会学习这些过滤器，它们会在“看到”（做点积）某些图片上的特征时激活，这些特征开始可能是一些局部特征，最后将会是一些整体特征。每一个过滤器会生成一个2维的激活图，我们在深度维度上堆叠这些激活图形成输出块。

**从大脑的角度分析。**如果你是一个大脑神经元分析的发烧友，3D输出块的每一个点可以解释为一个只看输入中一块小区域的神经元的输出，而空间上所有的神经元都共享参数。（因为这些结果都来自于一个相同的过滤器）我们现在讨论神经元连接，它们空间上的排列和它们共享参数的细节。

**局部连接。**当处理类似图片的高维度输入时，全连接是不可行的。取而代之的是只连接输入块的一个局部区域。这个连接的空间大小是一个叫做**接受域（receptive field）**的超参数（和过滤器大小相同），而连接的深度总是和输入块的深度相同。

![](http://cs231n.github.io/assets/cnn/depthcol.jpeg)

上图中，红色为一个大小为32x32x3的CIFAR-10图片的输入块，蓝色部分为一个卷积层的样例块。卷积层的每一个神经元只连接输入块空间上（宽和高）的一个局部区域，但是连接整个深度。换句话说，每个神经元就是一个过滤器和输入块上某一局部区域的点积结果。

![](http://cs231n.github.io/assets/nn1/neuron_model.jpeg)

普通神经网络中的神经元结构没变：依旧是计算权值和输入的点积（普通网络是矩阵乘积）然后跟随一个非线性单元，只是它们的链接被约束在一个局部区域。

**空间排列。**我们已经解释过CONV层中神经元和输入块之间的链接，但是还没有讨论输出块中有多少个神经元以及它们如何排列。三个超参数控制输出块的大小：**深度（depth），步长（stride）和0填充（zero-padding）**。

1. 首先，输出块的**深度**是一个超参数，它取决于我们想要用多少个过滤器，每一个过滤器学习去看输入中的不同东西。
2. 其次，我们必须设定**步长**用于滑动过滤器。步长为多少每次就滑动多少个像素，所以步长越大输出块越小。
3. 我们马上会看到，有时候为了方便我们需要在输入块周围填充0值，这个**0填充**的大小是一个超参数。0填充的好处是让我们能够控制输出块的大小。（最常见的是使输出块和输入块有相同的宽和高）

我们可以用一个函数计算输出块的空间大小，假设输入块大小为（\\(W\\)），CONV层接受域大小为（\\(F\\)），步长为（\\(S\\)），在边界上0填充的数量为（\\(P\\)），公式为\\((W - F + 2P)/S + 1\\)。

![](http://cs231n.github.io/assets/cnn/stride.jpeg)



---
© 2018 by 0ne.tech