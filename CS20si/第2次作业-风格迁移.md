# 第2次作业: 风格迁移

> [CS20si课程资料和代码Github地址](https://github.com/cnscott/Stanford-CS20si)

> [本次作业代码地址](https://github.com/cnscott/Stanford-CS20si/tree/master/assignments)

在这次作业中，你可以实现被热炒的神经风格迁移，神经风格非常酷，就连<<暮光之城>>的女主角贝拉的扮演者克里斯汀·斯图尔特也合写了一篇关于它的[论文](https://arxiv.org/pdf/1701.04928v1.pdf)。

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_StyleTransfer-Swim.jpg)

对于那些没有意识到炒作的人来说，风格转移是将一张图片的风格转移到另一张图片的任务。请阅读论文[A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) 来理解它的动机。

我们想要建立一个系统，输入两张图片（一张内容图片，一张风格图片），输出一张图片，内容和内容图片一样，风格和风格图片一样。

例如，用<<美国队长：内战>>中的死侍作为内容图片，将毕加索的<<格尔尼卡>>作为风格图片。

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Deadpool.png)

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Guernica.png)

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Deadpool-Guernica.png)

上面的图片很大（600x800），160次迭代用了大概1.5小时。用250x333的小图片大概需要15分钟。（译者用GTX1060 GPU大概3到5分钟完成800x600的图片）

更多的死侍风格：
![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Deadpool-Styles.jpg)
从左到右，从上到下分别是：文森特·梵高的<<星空>>、奥尔加·德罗兹多娃的<<图案>>、胡安·米罗的<<哈里昆的狂欢>>和萨尔瓦多·达利的<<变形的水仙>>。

这个模型在数学上并不困难，但是实现有点复杂，因为它在三个方面与我们实现的大多数模型不同：

1. 到目前为止的模型我们都是输入数据然后训练变量 - 我们不会修改原始的输入。 在这个模型中，你有两个固定的输入：内容图片和风格图片，但是还有一个可训练的输入，它会被训练成生成的艺术照。
2. 这里没有TensorFlow程序中两个阶段的明显区分：组装计算图然后执行它。全部的三个输入（内容图片，风格图片和可训练输入）拥有相同的维度，作为输入执行相同的计算来抽取相同的特征集。为了避免多次组装一样的子图，我们用一个变量处理三个输入。

		self.input_img = tf.get_variable('in_img', 
		                                 shape=([1, self.img_height, self.img_width, 3]),
		                                 dtype=tf.float32,
		                                 initializer=tf.zeros_initializer())

	我知道你在想“三个输入共享相同的变量是什么意思？TF怎么知道哪个是需要处理的输入？”你应该记得TF有assign运算可以给变量赋值。当我们要用内容图片作为输入计算的时候，将内容图片赋给这个变量。
3. 在这个作业里，你会逐渐了解迁移学习：我们在一个任务中使用为另一个任务训练的权重。我们将会使用为目标识别训练的VGG-19的权重来为风格迁移抽取内容层和风格层。关于VGG网络的更多内容，你可以看[这里](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)。Gatys团队的论文指出平均池比最大池要好，因此我们必须自己进行池化。

除此之外，这是一个典型的模型。记住在一个模型中，你需要做一些步骤：

- 步骤1：定义预测函数inference
- 步骤2：创建损失函数loss
- 步骤3：创建优化器optimizer
- 步骤4：创建摘要summaries来监控你的训练过程
- 步骤5：训练你的模型

在这个作业里你将逐步完成所有步骤。

在课程的GitHub中有3个文件作为作业的基础代码：

- **style_transfer.py** 是主文件，你需要修改它。
- **load_vgg.py** 是你加载预训练VGG变量的文件，你需要修改它。
- **utils.py** 包含这次作业的工具集，在有必要时修改它。

**styles**目录中包含一些图片，你可以用它们作为你的风格图片。**content**目录只有一张死侍的图片，你可以用它作为内容图片。

好了，准备好了吗？

### 第1步：定义预测函数inference
你应该修改**load_vgg.py**文件中的`conv2d_relu()`和`avgpool()`函数。

### 第2步：创建损失函数loss
你需要修改style_transfer.py中的函数`_content_loss()`, `_style_loss()`和它们所调用的函数`_single_style_loss()`和 `_gram_matrix()`。这部分有些复杂，所以请非常仔细的阅读照下面说明。

这里有两个损失：内容损失和风格损失，你需要最小化它们的和。内容损失定义如下：

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Content-Loss.jpg)

F是生成图片第I层的特征表示，P是内容图片第I层的特征表示。论文中建议我们使用‘conv4_2’层的特征表示。内容损失是F和P的均方误差（系数用1/4s代替1/2,s是P的元素个数）。

风格损失定义为：

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Style-Loss.jpg)

M是特征表示的空间维度的乘积，N是通道数。 例如在TensorFlow中conv2d的输入为(N,H,W,C)，在作业中N为1，M=HxW，N为C。 A是生成图片的Gram矩阵，G是风格图片的Gram矩阵。论文建议计算风格损失使用的5层特征表示为：

    ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']

当你计算完所有层的E值之后，就可以使用加权和计算风格损失，建议更深的层次用更大的权值。

当你获得了内容损失和风格损失之后，你可以用加权和计算总的损失，然后我们会尝试最小化损失。

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_Total-Loss.png)

论文建议我们使用alpha/beta=0.001或0.0001，但是实践中发现取1/20或1/50可以工作的很好。

### 第3步：创建优化器
建议使用AdamOptimizer，你也可以尝试其它优化器。

### 第4步：创建Summaries
你需在TensorBoard中在训练时记录你想要监控的运算的值。你可以在style_transfer.py中的`create_summary()`函数中找到它。

至少用200次迭代训练你的模型，并提交内容损失图、样式损失图、总损失图和模型计算图。你应该用最多3句话来描述你在损失图中看到了什么以及为什么是这样。

### 第5步：训练你的模型
你需要在style_transfer.py中修改`train()`函数中的TODO部分。你可以在StyleTransfer中的__init__方法中调整各种超参数。

最后你可以在outputs目录看看生成的图片了！下图是一张仙鹤图用梵高的星空进行风格转移后的图片。

![](http://images.cnblogs.com/cnblogs_com/tech0ne/1247403/o_299.png)